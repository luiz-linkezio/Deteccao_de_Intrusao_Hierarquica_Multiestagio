{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.metrics import classification_report\n",
    "#from sklearn.datasets import load_digits\n",
    "#from FirstStage import FirstStage\n",
    "#from SecondStage import SecondStage\n",
    "#from Extension import Extension\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cic_ids_2017 = pd.read_parquet(\"data/cic_ids_2017.parquet\")\n",
    "cse_cic_ids_2018 = pd.read_parquet(\"data/cse_cic_ids_2018.parquet\")\n",
    "#testp = pd.read_parquet(\"data/test.parquet\")\n",
    "#cic_collection = pd.read_parquet(\"data/cic-collection.parquet\")\n",
    "#infiltration_2018 = pd.read_parquet(\"data/infiltration_2018.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibindo o **.info()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2830743 entries, 0 to 2830742\n",
      "Data columns (total 79 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   Destination Port             int64  \n",
      " 1   Flow Duration                int64  \n",
      " 2   Total Fwd Packets            int64  \n",
      " 3   Total Backward Packets       int64  \n",
      " 4   Total Length of Fwd Packets  int64  \n",
      " 5   Total Length of Bwd Packets  int64  \n",
      " 6   Fwd Packet Length Max        int64  \n",
      " 7   Fwd Packet Length Min        int64  \n",
      " 8   Fwd Packet Length Mean       float64\n",
      " 9   Fwd Packet Length Std        float64\n",
      " 10  Bwd Packet Length Max        int64  \n",
      " 11  Bwd Packet Length Min        int64  \n",
      " 12  Bwd Packet Length Mean       float64\n",
      " 13  Bwd Packet Length Std        float64\n",
      " 14  Flow Bytes/s                 float64\n",
      " 15  Flow Packets/s               float64\n",
      " 16  Flow IAT Mean                float64\n",
      " 17  Flow IAT Std                 float64\n",
      " 18  Flow IAT Max                 int64  \n",
      " 19  Flow IAT Min                 int64  \n",
      " 20  Fwd IAT Total                int64  \n",
      " 21  Fwd IAT Mean                 float64\n",
      " 22  Fwd IAT Std                  float64\n",
      " 23  Fwd IAT Max                  int64  \n",
      " 24  Fwd IAT Min                  int64  \n",
      " 25  Bwd IAT Total                int64  \n",
      " 26  Bwd IAT Mean                 float64\n",
      " 27  Bwd IAT Std                  float64\n",
      " 28  Bwd IAT Max                  int64  \n",
      " 29  Bwd IAT Min                  int64  \n",
      " 30  Fwd PSH Flags                int64  \n",
      " 31  Bwd PSH Flags                int64  \n",
      " 32  Fwd URG Flags                int64  \n",
      " 33  Bwd URG Flags                int64  \n",
      " 34  Fwd Header Length            int64  \n",
      " 35  Bwd Header Length            int64  \n",
      " 36  Fwd Packets/s                float64\n",
      " 37  Bwd Packets/s                float64\n",
      " 38  Min Packet Length            int64  \n",
      " 39  Max Packet Length            int64  \n",
      " 40  Packet Length Mean           float64\n",
      " 41  Packet Length Std            float64\n",
      " 42  Packet Length Variance       float64\n",
      " 43  FIN Flag Count               int64  \n",
      " 44  SYN Flag Count               int64  \n",
      " 45  RST Flag Count               int64  \n",
      " 46  PSH Flag Count               int64  \n",
      " 47  ACK Flag Count               int64  \n",
      " 48  URG Flag Count               int64  \n",
      " 49  CWE Flag Count               int64  \n",
      " 50  ECE Flag Count               int64  \n",
      " 51  Down/Up Ratio                int64  \n",
      " 52  Average Packet Size          float64\n",
      " 53  Avg Fwd Segment Size         float64\n",
      " 54  Avg Bwd Segment Size         float64\n",
      " 55  Fwd Header Length.1          int64  \n",
      " 56  Fwd Avg Bytes/Bulk           int64  \n",
      " 57  Fwd Avg Packets/Bulk         int64  \n",
      " 58  Fwd Avg Bulk Rate            int64  \n",
      " 59  Bwd Avg Bytes/Bulk           int64  \n",
      " 60  Bwd Avg Packets/Bulk         int64  \n",
      " 61  Bwd Avg Bulk Rate            int64  \n",
      " 62  Subflow Fwd Packets          int64  \n",
      " 63  Subflow Fwd Bytes            int64  \n",
      " 64  Subflow Bwd Packets          int64  \n",
      " 65  Subflow Bwd Bytes            int64  \n",
      " 66  Init_Win_bytes_forward       int64  \n",
      " 67  Init_Win_bytes_backward      int64  \n",
      " 68  act_data_pkt_fwd             int64  \n",
      " 69  min_seg_size_forward         int64  \n",
      " 70  Active Mean                  float64\n",
      " 71  Active Std                   float64\n",
      " 72  Active Max                   int64  \n",
      " 73  Active Min                   int64  \n",
      " 74  Idle Mean                    float64\n",
      " 75  Idle Std                     float64\n",
      " 76  Idle Max                     int64  \n",
      " 77  Idle Min                     int64  \n",
      " 78  Label                        object \n",
      "dtypes: float64(24), int64(54), object(1)\n",
      "memory usage: 1.7+ GB\n"
     ]
    }
   ],
   "source": [
    "cic_ids_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16233002 entries, 0 to 16233001\n",
      "Data columns (total 78 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Timestamp          float64\n",
      " 1   Flow Duration      float64\n",
      " 2   Tot Fwd Pkts       float64\n",
      " 3   Tot Bwd Pkts       float64\n",
      " 4   TotLen Fwd Pkts    float64\n",
      " 5   TotLen Bwd Pkts    float64\n",
      " 6   Fwd Pkt Len Max    float64\n",
      " 7   Fwd Pkt Len Min    float64\n",
      " 8   Fwd Pkt Len Mean   float64\n",
      " 9   Fwd Pkt Len Std    float64\n",
      " 10  Bwd Pkt Len Max    float64\n",
      " 11  Bwd Pkt Len Min    float64\n",
      " 12  Bwd Pkt Len Mean   float64\n",
      " 13  Bwd Pkt Len Std    float64\n",
      " 14  Flow Byts/s        float64\n",
      " 15  Flow Pkts/s        float64\n",
      " 16  Flow IAT Mean      float64\n",
      " 17  Flow IAT Std       float64\n",
      " 18  Flow IAT Max       float64\n",
      " 19  Flow IAT Min       float64\n",
      " 20  Fwd IAT Tot        float64\n",
      " 21  Fwd IAT Mean       float64\n",
      " 22  Fwd IAT Std        float64\n",
      " 23  Fwd IAT Max        float64\n",
      " 24  Fwd IAT Min        float64\n",
      " 25  Bwd IAT Tot        float64\n",
      " 26  Bwd IAT Mean       float64\n",
      " 27  Bwd IAT Std        float64\n",
      " 28  Bwd IAT Max        float64\n",
      " 29  Bwd IAT Min        float64\n",
      " 30  Fwd PSH Flags      float64\n",
      " 31  Bwd PSH Flags      float64\n",
      " 32  Fwd URG Flags      float64\n",
      " 33  Bwd URG Flags      float64\n",
      " 34  Fwd Header Len     float64\n",
      " 35  Bwd Header Len     float64\n",
      " 36  Fwd Pkts/s         float64\n",
      " 37  Bwd Pkts/s         float64\n",
      " 38  Pkt Len Min        float64\n",
      " 39  Pkt Len Max        float64\n",
      " 40  Pkt Len Mean       float64\n",
      " 41  Pkt Len Std        float64\n",
      " 42  Pkt Len Var        float64\n",
      " 43  FIN Flag Cnt       float64\n",
      " 44  SYN Flag Cnt       float64\n",
      " 45  RST Flag Cnt       float64\n",
      " 46  PSH Flag Cnt       float64\n",
      " 47  ACK Flag Cnt       float64\n",
      " 48  URG Flag Cnt       float64\n",
      " 49  CWE Flag Count     float64\n",
      " 50  ECE Flag Cnt       float64\n",
      " 51  Down/Up Ratio      float64\n",
      " 52  Pkt Size Avg       float64\n",
      " 53  Fwd Seg Size Avg   float64\n",
      " 54  Bwd Seg Size Avg   float64\n",
      " 55  Fwd Byts/b Avg     float64\n",
      " 56  Fwd Pkts/b Avg     float64\n",
      " 57  Fwd Blk Rate Avg   float64\n",
      " 58  Bwd Byts/b Avg     float64\n",
      " 59  Bwd Pkts/b Avg     float64\n",
      " 60  Bwd Blk Rate Avg   float64\n",
      " 61  Subflow Fwd Pkts   float64\n",
      " 62  Subflow Fwd Byts   float64\n",
      " 63  Subflow Bwd Pkts   float64\n",
      " 64  Subflow Bwd Byts   float64\n",
      " 65  Init Fwd Win Byts  float64\n",
      " 66  Init Bwd Win Byts  float64\n",
      " 67  Fwd Act Data Pkts  float64\n",
      " 68  Fwd Seg Size Min   float64\n",
      " 69  Active Mean        float64\n",
      " 70  Active Std         float64\n",
      " 71  Active Max         float64\n",
      " 72  Active Min         float64\n",
      " 73  Idle Mean          float64\n",
      " 74  Idle Std           float64\n",
      " 75  Idle Max           float64\n",
      " 76  Idle Min           float64\n",
      " 77  Label              object \n",
      "dtypes: float64(77), object(1)\n",
      "memory usage: 9.4+ GB\n"
     ]
    }
   ],
   "source": [
    "cse_cic_ids_2018.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronizando e limpando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([cic_ids_2017, cse_cic_ids_2018], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza, pra liberar memória\n",
    "del cic_ids_2017\n",
    "del cse_cic_ids_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19063745 entries, 0 to 16233001\n",
      "Columns: 129 entries, Destination Port to Fwd Seg Size Min\n",
      "dtypes: float64(128), object(1)\n",
      "memory usage: 18.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alterando Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Benign                        13484708\n",
      "BENIGN                         2273097\n",
      "DDOS attack-HOIC                686012\n",
      "DDoS attacks-LOIC-HTTP          576191\n",
      "DoS attacks-Hulk                461912\n",
      "Bot                             288157\n",
      "DoS Hulk                        231073\n",
      "FTP-BruteForce                  193360\n",
      "SSH-Bruteforce                  187589\n",
      "Infilteration                   161934\n",
      "PortScan                        158930\n",
      "DoS attacks-SlowHTTPTest        139890\n",
      "DDoS                            128027\n",
      "DoS attacks-GoldenEye            41508\n",
      "DoS attacks-Slowloris            10990\n",
      "DoS GoldenEye                    10293\n",
      "FTP-Patator                       7938\n",
      "SSH-Patator                       5897\n",
      "DoS slowloris                     5796\n",
      "DoS Slowhttptest                  5499\n",
      "DDOS attack-LOIC-UDP              1730\n",
      "Web Attack � Brute Force          1507\n",
      "Web Attack � XSS                   652\n",
      "Brute Force -Web                   611\n",
      "Brute Force -XSS                   230\n",
      "SQL Injection                       87\n",
      "Label                               59\n",
      "Infiltration                        36\n",
      "Web Attack � Sql Injection          21\n",
      "Heartbleed                          11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 999)\n",
    "values_count = df['Label'].value_counts()\n",
    "print(values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padronizando labels e corrigindo labels redundantes/repetidas ou com caracteres irreconhecíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_changes = {'infilteration':'Infiltration', \n",
    "                 'Infilteration':'Infiltration',  \n",
    "                 'PortScan':'Port Scan', \n",
    "                 'Web Attack � Brute Force':'Brute Force-Web Attack', \n",
    "                 'Web Attack � XSS':'Web Attack-XSS', \n",
    "                 'Web Attack � Sql Injection':'Sql Injection-Web Attack', \n",
    "                 'DoS slowloris':'DoS Slowloris', \n",
    "                 'Benign':'BENIGN', \n",
    "                 'DoS Hulk':'DoS-Hulk', \n",
    "                 'DoS-Goldeneye':'DoS-GoldenEye', \n",
    "                 'DoS GoldenEye':'DoS-GoldenEye', \n",
    "                 'DoS Slowhttptest':'DoS-Slowhttptest', \n",
    "                 'DoS Slowloris':'DoS-Slowloris', \n",
    "                 'portscan':'Port Scan', \n",
    "                 'Webattack-bruteforce':'Brute Force-Web Attack', \n",
    "                 'Webattack-XSS':'Web Attack-XSS', \n",
    "                 'Webattack-SQLi':'Web Attack-SQLi', \n",
    "                 'DoS attacks-Hulk':'DoS-Hulk', \n",
    "                 'Brute Force -Web':'Brute Force-Web Attack', \n",
    "                 'DDoS attacks-LOIC-HTTP':'DDoS-LOIC-HTTP', \n",
    "                 'DDoS attack-HOIC':'DDoS-HOIC', \n",
    "                 'DDOS attack-LOIC-UDP':'DDOS-LOIC-UDP', \n",
    "                 'DoS attacks-SlowHTTPTest':'DoS-SlowHTTPTest', \n",
    "                 'DoS attacks-GoldenEye':'DoS-GoldenEye', \n",
    "                 'DoS attacks-Slowloris':'DoS-Slowloris', \n",
    "                 'SSH-Bruteforce':'Brute Force-SSH', \n",
    "                 'FTP-BruteForce':'Brute Force-FTP', \n",
    "                 'Brute Force -XSS':'Brute Force-XSS', \n",
    "                 'SSH-Patator':'Patator-SSH', \n",
    "                 'FTP-Patator':'Patator-FTP', \n",
    "                 'DDOS-LOIC-UDP':'DDoS-LOIC-UDP' }\n",
    "\n",
    "df['Label'] = df['Label'].replace(label_changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Heartbleed                        11\n",
      "Sql Injection-Web Attack          21\n",
      "Label                             59\n",
      "SQL Injection                     87\n",
      "Brute Force-XSS                  230\n",
      "Web Attack-XSS                   652\n",
      "DDOS-LOIC-UDP                   1730\n",
      "Brute Force-Web Attack          2118\n",
      "DoS-Slowhttptest                5499\n",
      "DoS Slowloris                   5796\n",
      "Patator-SSH                     5897\n",
      "Patator-FTP                     7938\n",
      "DoS-Slowloris                  10990\n",
      "DoS-GoldenEye                  51801\n",
      "DDoS                          128027\n",
      "DoS-SlowHTTPTest              139890\n",
      "Port Scan                     158930\n",
      "Infiltration                  161970\n",
      "Brute Force-SSH               187589\n",
      "Brute Force-FTP               193360\n",
      "Bot                           288157\n",
      "DDoS-LOIC-HTTP                576191\n",
      "DDOS attack-HOIC              686012\n",
      "DoS-Hulk                      692985\n",
      "BENIGN                      15757805\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "values_count = df['Label'].value_counts()\n",
    "print(values_count.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renomeando e removendo: linhas e colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo os dados que tem a string **Label** na coluna **Label**. Não faço ideia do que seja isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Label'] == 'Label'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo a coluna **Destination Port**, porque não existe muita correlação entre o tamanho do número da porta com a função da porta, por exemplo, não existe algo do tipo \"portas maiores tem uma função mais pra X, enquanto portas menores servem mais pra Y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Destination Port'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19063686 entries, 0 to 16233001\n",
      "Columns: 128 entries, Flow Duration to Fwd Seg Size Min\n",
      "dtypes: float64(127), object(1)\n",
      "memory usage: 18.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem algumas colunas que significam a mesma coisa, mas estão com nomes diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'coloração': 'cor'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10) # Retornando a um valor menor na exibição do Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibindo os registros não duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descartando registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_len = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "print(f'Tamanho inicial: {initial_len}, tamanho final {df.shape[0]} | Descartadas {initial_len - df.shape[0]} duplicadas')\n",
    "\n",
    "df = df.reset_index(drop=True) # Resetando index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros com valores não finitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns_isfinite = np.isfinite(df.drop(['Label'], axis='columns')).all(axis=0)\n",
    "df_columns_isfinite[df_columns_isfinite == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rows_isfinite = np.isfinite(df.drop(['Label'], axis='columns')).all(axis=1)\n",
    "inf_indexes = df_rows_isfinite[df_rows_isfinite == False].index\n",
    "df.iloc[inf_indexes][['Flow Bytes/s', 'Flow Packets/s']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando valores infinitos no maior valor finito encontrado na coluna, isso é feito para as duas colunas.\n",
    "\n",
    "Isso é feito porque a quantidade de registros infinitos é insignificante, seria inviável fazer isso em um conjunto de dados com muitos registros infinitos, pois existiriam muitos valores máximos e isso poderia comprometer o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_finite_flow_packets_per_sec = df[np.isfinite(df['Flow Packets/s'])]['Flow Packets/s'].max()\n",
    "max_finite_flow_bytes_per_sec = df[np.isfinite(df['Flow Bytes/s'])]['Flow Bytes/s'].max()\n",
    "\n",
    "df.loc[df['Flow Packets/s'] == np.inf, 'Flow Packets/s'] = max_finite_flow_packets_per_sec\n",
    "df.loc[df['Flow Bytes/s'] == np.inf, 'Flow Bytes/s'] = max_finite_flow_bytes_per_sec\n",
    "\n",
    "df = df.reset_index(drop=True) # Resetando index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros com valores Null/NaN/NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isna().any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isna().any(axis=1)][['Flow Bytes/s']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preenchendo registros NaN/Null/NA com a média dos valores de cada coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in tqdm(df.columns):\n",
    "    if column != \"Label\":\n",
    "        column_median = df[column].median()\n",
    "        df[column].fillna(column_median, inplace=True)\n",
    "\n",
    "df = df.reset_index(drop=True) # Resetando index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highly_correlated_features(correlation_matrix, threshold):\n",
    "  correlated_pairs = []\n",
    "  for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "      if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "        pair = (correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
    "        coefficient = correlation_matrix.iloc[i, j]\n",
    "        correlated_pairs.append((pair, coefficient))\n",
    "  return sorted(correlated_pairs, key= lambda pair: pair[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coletando as features correlacionadas, com o objetivo de evitar a redundância no treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_Label = df.drop('Label', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_without_Label.corr().abs()\n",
    "correlation_list = get_highly_correlated_features(corr_matrix, 0.95)\n",
    "\n",
    "# Limpeza\n",
    "del df_without_Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma lista do que será dropado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2drop = []\n",
    "for feature_pair, _ in correlation_list:\n",
    "  if feature_pair[0] not in f2drop and feature_pair[1] not in f2drop:\n",
    "    f2drop.append(feature_pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibindo as features correlacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo as features que atrapalham o modelo de aprendizagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(f2drop, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numeric_cols] = std_scaler.fit_transform(df[numeric_cols])\n",
    "#df = pd.DataFrame(std_scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpeza de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del f2drop\n",
    "del corr_matrix\n",
    "del correlation_list\n",
    "del df_columns_isfinite\n",
    "del df_rows_isfinite\n",
    "del inf_indexes\n",
    "del max_finite_flow_packets_per_sec\n",
    "del max_finite_flow_bytes_per_sec\n",
    "del initial_len\n",
    "del numeric_cols\n",
    "del std_scaler\n",
    "del label_changes\n",
    "del values_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados após o tratamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibindo o **.describe()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibindo o **.info()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividindo os dados (treino, validação, teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.query('Label == \"BENIGN\"').sample(frac=0.6)#, random_state=RANDOM_SEED)\n",
    "df_val_test = df.drop(df_train.index)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val_test = df_val_test.reset_index(drop=True)\n",
    "\n",
    "X_train = df_train.drop('Label', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, classes_val, classes_test = train_test_split(df_val_test.drop('Label', axis='columns'), df_val_test['Label'], test_size=0.65, stratify=df_val_test['Label']) #random_state=RANDOM_SEED)\n",
    "\n",
    "X_val, X_test = X_val.reset_index(drop=True), X_test.reset_index(drop=True)\n",
    "classes_val, classes_test =  classes_val.reset_index(drop=True), classes_test.reset_index(drop=True)\n",
    "\n",
    "y_val, y_test = classes_val.apply(lambda c: 0 if c == 'BENIGN' else 1), classes_test.apply(lambda c: 0 if c == 'BENIGN' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train, df_val_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignorar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor específico\n",
    "#valor_especifico = 'BENIGN'\n",
    "\n",
    "# Coleta de valores diferentes do valor específico\n",
    "#valores_diferentes = df.loc[df['Label'] != valor_especifico, 'Label'].tolist()\n",
    "\n",
    "#print(valores_diferentes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "#contagem_valores = df['Label'].value_counts()\n",
    "#print(contagem_valores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Z'] = df['X'] + df['Y']\n",
    "\n",
    "# Apagar as colunas X e Y\n",
    "#df.drop(columns=['X', 'Y'], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
